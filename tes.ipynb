{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6f58c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UTS Praktikum Pembelajaran Mesin - Kaggle Bot Account Detection\n",
    "\n",
    "# Import library yang dibutuhkan\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "db702e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LANGKAH 1: MEMBACA DAN EKSPLORASI DATA\n",
      "--------------------------------------------------\n",
      "Informasi Dasar Dataset:\n",
      "Jumlah Baris: 1321188\n",
      "Jumlah Kolom: 17\n",
      "\n",
      "Tipe Data dan Missing Values:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1321188 entries, 0 to 1321187\n",
      "Data columns (total 17 columns):\n",
      " #   Column                 Non-Null Count    Dtype  \n",
      "---  ------                 --------------    -----  \n",
      " 0   Unnamed: 0             1321188 non-null  int64  \n",
      " 1   NAME                   1243024 non-null  object \n",
      " 2   GENDER                 1243309 non-null  object \n",
      " 3   EMAIL_ID               1243374 non-null  object \n",
      " 4   IS_GLOGIN              1243272 non-null  object \n",
      " 5   FOLLOWER_COUNT         1243476 non-null  float64\n",
      " 6   FOLLOWING_COUNT        1242743 non-null  float64\n",
      " 7   DATASET_COUNT          1242621 non-null  float64\n",
      " 8   CODE_COUNT             1243262 non-null  float64\n",
      " 9   DISCUSSION_COUNT       1243466 non-null  float64\n",
      " 10  AVG_NB_READ_TIME_MIN   1242872 non-null  float64\n",
      " 11  REGISTRATION_IPV4      1242859 non-null  object \n",
      " 12  REGISTRATION_LOCATION  1242898 non-null  object \n",
      " 13  TOTAL_VOTES_GAVE_NB    1243483 non-null  float64\n",
      " 14  TOTAL_VOTES_GAVE_DS    1243254 non-null  float64\n",
      " 15  TOTAL_VOTES_GAVE_DC    1243158 non-null  float64\n",
      " 16  ISBOT                  1242688 non-null  object \n",
      "dtypes: float64(9), int64(1), object(7)\n",
      "memory usage: 171.4+ MB\n",
      "None\n",
      "\n",
      "Sampel Data (5 baris pertama):\n",
      "   Unnamed: 0                     NAME  GENDER                    EMAIL_ID  \\\n",
      "0           0        Johnny KerrThomas    Male     jacksonalan@example.com   \n",
      "1           1        Dwayne LarsenLara    Male        calvin80@example.com   \n",
      "2           2                      NaN    Male          qbrown@example.net   \n",
      "3           3  Russell SimmonsPhillips    Male  kimberlywagner@example.com   \n",
      "4           4     Jamie WilsonMartinez  Female     shaunbrooks@example.com   \n",
      "\n",
      "  IS_GLOGIN  FOLLOWER_COUNT  FOLLOWING_COUNT  DATASET_COUNT  CODE_COUNT  \\\n",
      "0     False            53.0             87.0            5.0         3.0   \n",
      "1      True            16.0             67.0            5.0         NaN   \n",
      "2      True            44.0             81.0            4.0        17.0   \n",
      "3      True            23.0            114.0            5.0        24.0   \n",
      "4     False            46.0            112.0            2.0        12.0   \n",
      "\n",
      "   DISCUSSION_COUNT  AVG_NB_READ_TIME_MIN REGISTRATION_IPV4  \\\n",
      "0             124.0                   NaN      81.88.75.170   \n",
      "1              26.0                 24.97               NaN   \n",
      "2             125.0                  7.75   159.202.103.178   \n",
      "3              67.0                 13.40     196.11.132.51   \n",
      "4              63.0                 24.83    159.196.199.20   \n",
      "\n",
      "  REGISTRATION_LOCATION  TOTAL_VOTES_GAVE_NB  TOTAL_VOTES_GAVE_DS  \\\n",
      "0             Argentina                 16.0                 10.0   \n",
      "1           New Zealand                 14.0                  5.0   \n",
      "2            Costa Rica                 16.0                  4.0   \n",
      "3                 Italy                 21.0                 10.0   \n",
      "4               Belgium                 10.0                  6.0   \n",
      "\n",
      "   TOTAL_VOTES_GAVE_DC  ISBOT  \n",
      "0                  3.0    NaN  \n",
      "1                  2.0    NaN  \n",
      "2                  0.0  False  \n",
      "3                  1.0  False  \n",
      "4                  2.0  False  \n"
     ]
    }
   ],
   "source": [
    "# 1. MEMBACA DAN EKSPLORASI DATA\n",
    "print(\"LANGKAH 1: MEMBACA DAN EKSPLORASI DATA\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Membaca dataset\n",
    "dataset_path = \"../dataset/kaggle_bot_accounts.csv\"\n",
    "data = pd.read_csv(dataset_path)\n",
    "\n",
    "# Melihat struktur data\n",
    "print(\"Informasi Dasar Dataset:\")\n",
    "print(f\"Jumlah Baris: {data.shape[0]}\")\n",
    "print(f\"Jumlah Kolom: {data.shape[1]}\")\n",
    "print(\"\\nTipe Data dan Missing Values:\")\n",
    "print(data.info())\n",
    "\n",
    "# Melihat sampel data\n",
    "print(\"\\nSampel Data (5 baris pertama):\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1598bba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LANGKAH 2: EXPLORATORY DATA ANALYSIS (EDA)\n",
      "--------------------------------------------------\n",
      "Jumlah Missing Values per Kolom:\n",
      "NAME                     78164\n",
      "GENDER                   77879\n",
      "EMAIL_ID                 77814\n",
      "IS_GLOGIN                77916\n",
      "FOLLOWER_COUNT           77712\n",
      "FOLLOWING_COUNT          78445\n",
      "DATASET_COUNT            78567\n",
      "CODE_COUNT               77926\n",
      "DISCUSSION_COUNT         77722\n",
      "AVG_NB_READ_TIME_MIN     78316\n",
      "REGISTRATION_IPV4        78329\n",
      "REGISTRATION_LOCATION    78290\n",
      "TOTAL_VOTES_GAVE_NB      77705\n",
      "TOTAL_VOTES_GAVE_DS      77934\n",
      "TOTAL_VOTES_GAVE_DC      78030\n",
      "ISBOT                    78500\n",
      "dtype: int64\n",
      "\n",
      "Jumlah Duplikat dalam Dataset: 0\n",
      "\n",
      "Statistik Deskriptif untuk Fitur Numerik:\n",
      "         Unnamed: 0  FOLLOWER_COUNT  FOLLOWING_COUNT  DATASET_COUNT  \\\n",
      "count  1.321188e+06    1.243476e+06     1.242743e+06   1.242621e+06   \n",
      "mean   6.605935e+05    2.698273e+01     4.505091e+01   2.562564e+00   \n",
      "std    3.813943e+05    2.300504e+01     3.947716e+01   2.499882e+00   \n",
      "min    0.000000e+00    0.000000e+00     0.000000e+00   0.000000e+00   \n",
      "25%    3.302968e+05    2.000000e+00     3.000000e+00   0.000000e+00   \n",
      "50%    6.605935e+05    2.400000e+01     3.900000e+01   2.000000e+00   \n",
      "75%    9.908902e+05    4.700000e+01     8.000000e+01   5.000000e+00   \n",
      "max    1.321187e+06    7.000000e+01     1.200000e+02   7.000000e+00   \n",
      "\n",
      "         CODE_COUNT  DISCUSSION_COUNT  AVG_NB_READ_TIME_MIN  \\\n",
      "count  1.243262e+06      1.243466e+06          1.242872e+06   \n",
      "mean   1.038450e+01      6.584244e+01          1.274225e+01   \n",
      "std    8.248055e+00      4.754315e+01          9.564920e+00   \n",
      "min    0.000000e+00      0.000000e+00          0.000000e+00   \n",
      "25%    1.000000e+00      1.300000e+01          1.870000e+00   \n",
      "50%    1.000000e+01      6.500000e+01          1.229000e+01   \n",
      "75%    1.800000e+01      1.080000e+02          2.119000e+01   \n",
      "max    2.500000e+01      1.500000e+02          2.999000e+01   \n",
      "\n",
      "       TOTAL_VOTES_GAVE_NB  TOTAL_VOTES_GAVE_DS  TOTAL_VOTES_GAVE_DC  \n",
      "count         1.243483e+06         1.243254e+06         1.243158e+06  \n",
      "mean          1.750656e+01         6.501007e+00         1.500373e+00  \n",
      "std           4.611783e+00         2.290951e+00         1.118067e+00  \n",
      "min           1.000000e+01         3.000000e+00         0.000000e+00  \n",
      "25%           1.400000e+01         5.000000e+00         1.000000e+00  \n",
      "50%           1.800000e+01         7.000000e+00         2.000000e+00  \n",
      "75%           2.200000e+01         9.000000e+00         3.000000e+00  \n",
      "max           2.500000e+01         1.000000e+01         3.000000e+00  \n",
      "\n",
      "Distribusi Target (ISBOT):\n",
      "ISBOT\n",
      "False    909794\n",
      "True     332894\n",
      "NaN       78500\n",
      "Name: count, dtype: int64\n",
      "Persentase Missing Values Target: 5.94%\n"
     ]
    }
   ],
   "source": [
    "# 2. EXPLORATORY DATA ANALYSIS (EDA)\n",
    "print(\"\\nLANGKAH 2: EXPLORATORY DATA ANALYSIS (EDA)\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Menghitung jumlah missing value setiap kolom\n",
    "missing_values = data.isnull().sum()\n",
    "print(\"Jumlah Missing Values per Kolom:\")\n",
    "print(missing_values[missing_values > 0])\n",
    "\n",
    "# Memeriksa duplikat\n",
    "duplicates = data.duplicated().sum()\n",
    "print(f\"\\nJumlah Duplikat dalam Dataset: {duplicates}\")\n",
    "\n",
    "# Statistik deskriptif untuk kolom numerik\n",
    "print(\"\\nStatistik Deskriptif untuk Fitur Numerik:\")\n",
    "print(data.describe())\n",
    "\n",
    "# Menghitung distribusi kelas target (ISBOT)\n",
    "print(\"\\nDistribusi Target (ISBOT):\")\n",
    "print(data['ISBOT'].value_counts(dropna=False))\n",
    "print(f\"Persentase Missing Values Target: {data['ISBOT'].isnull().mean() * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa32934b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 3. DATA PREPROCESSING\n",
    "# print(\"\\nLANGKAH 3: DATA PREPROCESSING\")\n",
    "# print(\"-\" * 50)\n",
    "\n",
    "# # 3.1 Menangani missing values\n",
    "# print(\"3.1 Menangani Missing Values\")\n",
    "\n",
    "# # Menghapus duplikat jika ada\n",
    "# data = data.drop_duplicates().reset_index(drop=True)\n",
    "# print(f\"Jumlah baris setelah menghapus duplikat: {data.shape[0]}\")\n",
    "\n",
    "# # Menangani missing values pada kolom target (ISBOT)\n",
    "# # Menghapus baris yang tidak memiliki label target\n",
    "# if data['ISBOT'].isnull().sum() > 0:\n",
    "#     data_labeled = data.dropna(subset=['ISBOT']).reset_index(drop=True)\n",
    "#     print(f\"Jumlah baris setelah menghapus baris tanpa label: {data_labeled.shape[0]}\")\n",
    "# else:\n",
    "#     data_labeled = data.copy()\n",
    "\n",
    "# # Fitur dan target\n",
    "# X = data_labeled.drop('ISBOT', axis=1)\n",
    "# y = data_labeled['ISBOT'].astype(int)  # Mengkonversi ke tipe int (0 untuk False, 1 untuk True)\n",
    "\n",
    "# # Pembagian fitur kategorikal dan numerik\n",
    "# categorical_cols = ['NAME', 'GENDER', 'EMAIL_ID', 'IS_GLOGIN', 'REGISTRATION_LOCATION']\n",
    "# numerical_cols = ['FOLLOWER_COUNT', 'FOLLOWING_COUNT', 'DATASET_COUNT', 'CODE_COUNT', \n",
    "#                  'DISCUSSION_COUNT', 'AVG_NB_READ_TIME_MIN', 'TOTAL_VOTES_GAVE_NB', \n",
    "#                  'TOTAL_VOTES_GAVE_DS', 'TOTAL_VOTES_GAVE_DC']\n",
    "# binary_cols = ['IS_GLOGIN']  # Kolom boolean\n",
    "\n",
    "# # Imputasi nilai yang hilang\n",
    "# print(\"\\n3.2 Imputasi Missing Values\")\n",
    "\n",
    "# # Untuk fitur kategorikal, imputasi dengan mode (nilai yang paling sering muncul)\n",
    "# # Untuk fitur numerik, imputasi dengan median\n",
    "# print(f\"Fitur kategorikal: {categorical_cols}\")\n",
    "# print(f\"Fitur numerik: {numerical_cols}\")\n",
    "\n",
    "# # Memeriksa korelasi antar fitur numerik\n",
    "# print(\"\\n3.3 Analisis Korelasi Antar Fitur Numerik\")\n",
    "# numerical_data = X[numerical_cols].copy()\n",
    "\n",
    "# # Imputasi missing values untuk perhitungan korelasi\n",
    "# imputer = SimpleImputer(strategy='median')\n",
    "# numerical_data_imputed = pd.DataFrame(\n",
    "#     imputer.fit_transform(numerical_data),\n",
    "#     columns=numerical_data.columns\n",
    "# )\n",
    "\n",
    "# # Hitung korelasi\n",
    "# correlation_matrix = numerical_data_imputed.corr()\n",
    "\n",
    "# # Plot heatmap korelasi\n",
    "# plt.figure(figsize=(12, 10))\n",
    "# sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "# plt.title('Matriks Korelasi Fitur Numerik')\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('../dataset/correlation_heatmap.png')  # Simpan gambar korelasi\n",
    "# plt.close()\n",
    "\n",
    "# print(\"Heatmap korelasi telah disimpan sebagai 'correlation_heatmap.png'\")\n",
    "\n",
    "# # 3.4 Pemrosesan Data dan Encoding\n",
    "# print(\"\\n3.4 Pemrosesan Data dan Feature Engineering\")\n",
    "\n",
    "# # Preprocessing untuk fitur kategorikal dan numerik\n",
    "# categorical_transformer = Pipeline(steps=[\n",
    "#     ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "#     ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "# ])\n",
    "\n",
    "# numerical_transformer = Pipeline(steps=[\n",
    "#     ('imputer', SimpleImputer(strategy='median')),\n",
    "#     ('scaler', StandardScaler())\n",
    "# ])\n",
    "\n",
    "# # Gabungkan preprocessing untuk semua fitur\n",
    "# preprocessor = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         ('num', numerical_transformer, numerical_cols),\n",
    "#         ('cat', categorical_transformer, [col for col in categorical_cols if col not in binary_cols])\n",
    "#     ],\n",
    "#     remainder='drop'  # Kolom lain diabaikan\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3bcb1167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LANGKAH 3: DATA PREPROCESSING\n",
      "--------------------------------------------------\n",
      "3.1 Menangani Missing Values\n",
      "Jumlah baris setelah menghapus duplikat: 1321188\n",
      "Jumlah baris setelah menghapus baris tanpa label: 1242688\n",
      "\n",
      "3.2 Modifikasi Fitur untuk Mengurangi Kardinalitas\n",
      "\n",
      "3.3 Imputasi Missing Values\n",
      "Fitur kategorikal: ['GENDER', 'IS_GLOGIN', 'EMAIL_DOMAIN']\n",
      "Fitur numerik: ['FOLLOWER_COUNT', 'FOLLOWING_COUNT', 'DATASET_COUNT', 'CODE_COUNT', 'DISCUSSION_COUNT', 'AVG_NB_READ_TIME_MIN', 'TOTAL_VOTES_GAVE_NB', 'TOTAL_VOTES_GAVE_DS', 'TOTAL_VOTES_GAVE_DC', 'NAME_LENGTH']\n",
      "\n",
      "3.4 Analisis Korelasi Antar Fitur Numerik\n",
      "Heatmap korelasi telah disimpan sebagai 'correlation_heatmap.png'\n",
      "\n",
      "3.5 Pemrosesan Data dan Feature Engineering\n"
     ]
    }
   ],
   "source": [
    "# 3. DATA PREPROCESSING\n",
    "print(\"\\nLANGKAH 3: DATA PREPROCESSING\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# 3.1 Menangani missing values\n",
    "print(\"3.1 Menangani Missing Values\")\n",
    "\n",
    "# Menghapus duplikat jika ada\n",
    "data = data.drop_duplicates().reset_index(drop=True)\n",
    "print(f\"Jumlah baris setelah menghapus duplikat: {data.shape[0]}\")\n",
    "\n",
    "# Menangani missing values pada kolom target (ISBOT)\n",
    "# Menghapus baris yang tidak memiliki label target\n",
    "if data['ISBOT'].isnull().sum() > 0:\n",
    "    data_labeled = data.dropna(subset=['ISBOT']).reset_index(drop=True)\n",
    "    print(f\"Jumlah baris setelah menghapus baris tanpa label: {data_labeled.shape[0]}\")\n",
    "else:\n",
    "    data_labeled = data.copy()\n",
    "\n",
    "# Fitur dan target\n",
    "X = data_labeled.drop('ISBOT', axis=1)\n",
    "y = data_labeled['ISBOT'].astype(int)  # Mengkonversi ke tipe int (0 untuk False, 1 untuk True)\n",
    "\n",
    "# 3.2 Modifikasi fitur kategorikal untuk mengurangi kardinalitas\n",
    "print(\"\\n3.2 Modifikasi Fitur untuk Mengurangi Kardinalitas\")\n",
    "\n",
    "# Modifikasi fitur kategorikal - gunakan hanya yang kardinalitas rendah\n",
    "categorical_cols = ['GENDER', 'IS_GLOGIN']  # Hapus NAME, EMAIL_ID, dan REGISTRATION_LOCATION\n",
    "numerical_cols = ['FOLLOWER_COUNT', 'FOLLOWING_COUNT', 'DATASET_COUNT', 'CODE_COUNT', \n",
    "                 'DISCUSSION_COUNT', 'AVG_NB_READ_TIME_MIN', 'TOTAL_VOTES_GAVE_NB', \n",
    "                 'TOTAL_VOTES_GAVE_DS', 'TOTAL_VOTES_GAVE_DC']\n",
    "binary_cols = ['IS_GLOGIN']  # Kolom boolean\n",
    "\n",
    "# Tambahkan feature engineering sederhana untuk kolom lain\n",
    "# Extract domain dari email (jika perlu dan jika kolom ada)\n",
    "if 'EMAIL_ID' in X.columns and X['EMAIL_ID'].isnull().sum() < len(X['EMAIL_ID']):\n",
    "    X['EMAIL_DOMAIN'] = X['EMAIL_ID'].fillna('').apply(lambda x: x.split('@')[1] if '@' in x else '')\n",
    "    categorical_cols.append('EMAIL_DOMAIN')\n",
    "\n",
    "# Tambahkan feature engineering untuk NAME (panjang nama)\n",
    "if 'NAME' in X.columns:\n",
    "    X['NAME_LENGTH'] = X['NAME'].fillna('').apply(len)\n",
    "    numerical_cols.append('NAME_LENGTH')\n",
    "\n",
    "# Imputasi nilai yang hilang\n",
    "print(\"\\n3.3 Imputasi Missing Values\")\n",
    "print(f\"Fitur kategorikal: {categorical_cols}\")\n",
    "print(f\"Fitur numerik: {numerical_cols}\")\n",
    "\n",
    "# Memeriksa korelasi antar fitur numerik\n",
    "print(\"\\n3.4 Analisis Korelasi Antar Fitur Numerik\")\n",
    "numerical_data = X[numerical_cols].copy()\n",
    "\n",
    "# Imputasi missing values untuk perhitungan korelasi\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "numerical_data_imputed = pd.DataFrame(\n",
    "    imputer.fit_transform(numerical_data),\n",
    "    columns=numerical_data.columns\n",
    ")\n",
    "\n",
    "# Hitung korelasi\n",
    "correlation_matrix = numerical_data_imputed.corr()\n",
    "\n",
    "# Plot heatmap korelasi\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "plt.title('Matriks Korelasi Fitur Numerik')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../dataset/correlation_heatmap.png')  # Simpan gambar korelasi\n",
    "plt.close()\n",
    "\n",
    "print(\"Heatmap korelasi telah disimpan sebagai 'correlation_heatmap.png'\")\n",
    "\n",
    "# 3.5 Pemrosesan Data dan Feature Engineering\n",
    "print(\"\\n3.5 Pemrosesan Data dan Feature Engineering\")\n",
    "\n",
    "# Preprocessing untuk fitur kategorikal dan numerik\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Gabungkan preprocessing untuk semua fitur\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, [col for col in categorical_cols if col not in binary_cols])\n",
    "    ],\n",
    "    remainder='drop'  # Kolom lain diabaikan\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9acb5e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LANGKAH 4: PEMISAHAN DATA TRAINING DAN TESTING\n",
      "--------------------------------------------------\n",
      "Ukuran data training: 994150 sampel\n",
      "Ukuran data testing: 248538 sampel\n",
      "\n",
      "Distribusi kelas pada data training:\n",
      "ISBOT\n",
      "0    73.21%\n",
      "1    26.79%\n",
      "Name: proportion, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 4. PEMISAHAN DATA TRAINING DAN TESTING\n",
    "print(\"\\nLANGKAH 4: PEMISAHAN DATA TRAINING DAN TESTING\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print(f\"Ukuran data training: {X_train.shape[0]} sampel\")\n",
    "print(f\"Ukuran data testing: {X_test.shape[0]} sampel\")\n",
    "\n",
    "# Cek distribusi kelas di data training\n",
    "print(\"\\nDistribusi kelas pada data training:\")\n",
    "print(pd.Series(y_train).value_counts(normalize=True).apply(lambda x: f\"{x:.2%}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92e34c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 5. MENGATASI IMBALANCED DATASET\n",
    "# print(\"\\nLANGKAH 5: MENGATASI IMBALANCED DATASET\")\n",
    "# print(\"-\" * 50)\n",
    "\n",
    "# # Periksa keseimbangan kelas\n",
    "# class_counts = pd.Series(y_train).value_counts()\n",
    "# print(\"Jumlah sampel per kelas sebelum SMOTE:\")\n",
    "# print(class_counts)\n",
    "\n",
    "# # Terapkan SMOTE untuk mengatasi ketidakseimbangan\n",
    "# X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "# smote = SMOTE(random_state=42)\n",
    "# X_train_resampled, y_train_resampled = smote.fit_resample(X_train_preprocessed, y_train)\n",
    "\n",
    "# print(f\"\\nJumlah sampel sebelum SMOTE: {len(y_train)}\")\n",
    "# print(f\"Jumlah sampel setelah SMOTE: {len(y_train_resampled)}\")\n",
    "# print(\"Distribusi kelas setelah SMOTE:\")\n",
    "# print(pd.Series(y_train_resampled).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b8fe6fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LANGKAH 5: MENGATASI IMBALANCED DATASET\n",
      "--------------------------------------------------\n",
      "Jumlah sampel per kelas sebelum SMOTE:\n",
      "ISBOT\n",
      "0    727835\n",
      "1    266315\n",
      "Name: count, dtype: int64\n",
      "Rasio ketidakseimbangan: 0.3659\n",
      "\n",
      "Data cukup seimbang, tidak perlu SMOTE\n"
     ]
    }
   ],
   "source": [
    "# 5. MENGATASI IMBALANCED DATASET\n",
    "print(\"\\nLANGKAH 5: MENGATASI IMBALANCED DATASET\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Periksa keseimbangan kelas\n",
    "class_counts = pd.Series(y_train).value_counts()\n",
    "print(\"Jumlah sampel per kelas sebelum SMOTE:\")\n",
    "print(class_counts)\n",
    "\n",
    "# Cek apakah perlu SMOTE\n",
    "imbalance_ratio = class_counts.min() / class_counts.max()\n",
    "print(f\"Rasio ketidakseimbangan: {imbalance_ratio:.4f}\")\n",
    "\n",
    "# Jika rasio imbalance di bawah 0.2, gunakan SMOTE dengan sampling rate yang lebih rendah\n",
    "if imbalance_ratio < 0.2:\n",
    "    # Terapkan preprocessing terlebih dahulu\n",
    "    X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "    \n",
    "    # Gunakan SMOTE dengan sampling_strategy yang lebih rendah\n",
    "    sampling_strategy = min(0.5, imbalance_ratio * 2)  # Jangan buat seimbang sempurna\n",
    "    smote = SMOTE(random_state=42, sampling_strategy=sampling_strategy)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train_preprocessed, y_train)\n",
    "    \n",
    "    print(f\"\\nJumlah sampel sebelum SMOTE: {len(y_train)}\")\n",
    "    print(f\"Jumlah sampel setelah SMOTE: {len(y_train_resampled)}\")\n",
    "    print(\"Distribusi kelas setelah SMOTE:\")\n",
    "    print(pd.Series(y_train_resampled).value_counts())\n",
    "else:\n",
    "    # Jika rasio cukup seimbang, gunakan data asli\n",
    "    X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "    X_train_resampled, y_train_resampled = X_train_preprocessed, y_train\n",
    "    print(\"\\nData cukup seimbang, tidak perlu SMOTE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1d6a4678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LANGKAH 6: MODEL BASELINE\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 12\u001b[0m\n\u001b[0;32m      6\u001b[0m rf_pipeline \u001b[38;5;241m=\u001b[39m Pipeline(steps\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m      7\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessor\u001b[39m\u001b[38;5;124m'\u001b[39m, preprocessor),\n\u001b[0;32m      8\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m'\u001b[39m, RandomForestClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m))\n\u001b[0;32m      9\u001b[0m ])\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Latih model baseline\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[43mrf_pipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Evaluasi model baseline\u001b[39;00m\n\u001b[0;32m     15\u001b[0m y_pred_baseline \u001b[38;5;241m=\u001b[39m rf_pipeline\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32md:\\__mata kuliah\\machine learning\\env\\virEnvironment\\lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\__mata kuliah\\machine learning\\env\\virEnvironment\\lib\\site-packages\\sklearn\\pipeline.py:662\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    656\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    657\u001b[0m         last_step_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_metadata_for_step(\n\u001b[0;32m    658\u001b[0m             step_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    659\u001b[0m             step_params\u001b[38;5;241m=\u001b[39mrouted_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]],\n\u001b[0;32m    660\u001b[0m             all_params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m    661\u001b[0m         )\n\u001b[1;32m--> 662\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator\u001b[38;5;241m.\u001b[39mfit(Xt, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlast_step_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    664\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32md:\\__mata kuliah\\machine learning\\env\\virEnvironment\\lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\__mata kuliah\\machine learning\\env\\virEnvironment\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:487\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    476\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    479\u001b[0m ]\n\u001b[0;32m    481\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 487\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32md:\\__mata kuliah\\machine learning\\env\\virEnvironment\\lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\__mata kuliah\\machine learning\\env\\virEnvironment\\lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32md:\\__mata kuliah\\machine learning\\env\\virEnvironment\\lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32md:\\__mata kuliah\\machine learning\\env\\virEnvironment\\lib\\site-packages\\sklearn\\utils\\parallel.py:139\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\__mata kuliah\\machine learning\\env\\virEnvironment\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:189\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    187\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 189\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    197\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m    198\u001b[0m         X,\n\u001b[0;32m    199\u001b[0m         y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    202\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[0;32m    203\u001b[0m     )\n",
      "File \u001b[1;32md:\\__mata kuliah\\machine learning\\env\\virEnvironment\\lib\\site-packages\\sklearn\\tree\\_classes.py:295\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_classification:\n\u001b[0;32m    294\u001b[0m     check_classification_targets(y)\n\u001b[1;32m--> 295\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    297\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    298\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32md:\\__mata kuliah\\machine learning\\env\\virEnvironment\\lib\\site-packages\\numpy\\lib\\_function_base_impl.py:978\u001b[0m, in \u001b[0;36mcopy\u001b[1;34m(a, order, subok)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_copy_dispatcher)\n\u001b[0;32m    909\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcopy\u001b[39m(a, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mK\u001b[39m\u001b[38;5;124m'\u001b[39m, subok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    910\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    911\u001b[0m \u001b[38;5;124;03m    Return an array copy of the given object.\u001b[39;00m\n\u001b[0;32m    912\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    976\u001b[0m \u001b[38;5;124;03m    array([3, 2, 3])\u001b[39;00m\n\u001b[0;32m    977\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 978\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubok\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 6. MODEL BASELINE\n",
    "print(\"\\nLANGKAH 6: MODEL BASELINE\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Buat pipeline untuk Random Forest sebagai baseline\n",
    "rf_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Latih model baseline\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluasi model baseline\n",
    "y_pred_baseline = rf_pipeline.predict(X_test)\n",
    "print(\"Kinerja Model Baseline (Random Forest):\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_baseline):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_baseline):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_baseline):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred_baseline):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaa6a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. HYPERPARAMETER TUNING DAN CROSS-VALIDATION\n",
    "print(\"\\nLANGKAH 7: HYPERPARAMETER TUNING DAN CROSS-VALIDATION\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# 7.1 Random Forest Tuning\n",
    "print(\"7.1 Random Forest Hyperparameter Tuning\")\n",
    "\n",
    "param_grid_rf = {\n",
    "    'classifier__n_estimators': [50, 100, 200],\n",
    "    'classifier__max_depth': [None, 10, 20],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Gunakan GridSearchCV dengan cross-validation\n",
    "grid_search_rf = GridSearchCV(\n",
    "    rf_pipeline,\n",
    "    param_grid_rf,\n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\nParameter terbaik untuk Random Forest: {grid_search_rf.best_params_}\")\n",
    "print(f\"F1 Score terbaik untuk Random Forest: {grid_search_rf.best_score_:.4f}\")\n",
    "\n",
    "# 7.2 Gradient Boosting Tuning\n",
    "print(\"\\n7.2 Gradient Boosting Hyperparameter Tuning\")\n",
    "\n",
    "# Buat pipeline untuk Gradient Boosting\n",
    "gb_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', GradientBoostingClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "param_grid_gb = {\n",
    "    'classifier__n_estimators': [50, 100, 200],\n",
    "    'classifier__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'classifier__max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "# Gunakan GridSearchCV dengan cross-validation\n",
    "grid_search_gb = GridSearchCV(\n",
    "    gb_pipeline,\n",
    "    param_grid_gb,\n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search_gb.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\nParameter terbaik untuk Gradient Boosting: {grid_search_gb.best_params_}\")\n",
    "print(f\"F1 Score terbaik untuk Gradient Boosting: {grid_search_gb.best_score_:.4f}\")\n",
    "\n",
    "# 7.3 Logistic Regression Tuning\n",
    "print(\"\\n7.3 Logistic Regression Hyperparameter Tuning\")\n",
    "\n",
    "# Buat pipeline untuk Logistic Regression\n",
    "lr_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(random_state=42, max_iter=1000))\n",
    "])\n",
    "\n",
    "param_grid_lr = {\n",
    "    'classifier__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'classifier__solver': ['liblinear', 'lbfgs'],\n",
    "    'classifier__penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "# Gunakan GridSearchCV dengan cross-validation\n",
    "grid_search_lr = GridSearchCV(\n",
    "    lr_pipeline,\n",
    "    param_grid_lr,\n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search_lr.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\nParameter terbaik untuk Logistic Regression: {grid_search_lr.best_params_}\")\n",
    "print(f\"F1 Score terbaik untuk Logistic Regression: {grid_search_lr.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f863f89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. ENSEMBLE LEARNING\n",
    "print(\"\\nLANGKAH 8: ENSEMBLE LEARNING\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# 8.1 Buat model dengan parameter terbaik\n",
    "best_rf = grid_search_rf.best_estimator_\n",
    "best_gb = grid_search_gb.best_estimator_\n",
    "best_lr = grid_search_lr.best_estimator_\n",
    "\n",
    "# 8.2 Buat model ensemble dengan Voting Classifier\n",
    "ensemble_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', best_rf),\n",
    "        ('gb', best_gb),\n",
    "        ('lr', best_lr)\n",
    "    ],\n",
    "    voting='soft'  # Gunakan probabilitas untuk voting\n",
    ")\n",
    "\n",
    "# Latih model ensemble\n",
    "ensemble_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluasi model ensemble\n",
    "y_pred_ensemble = ensemble_clf.predict(X_test)\n",
    "print(\"Kinerja Model Ensemble:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_ensemble):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_ensemble):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_ensemble):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred_ensemble):.4f}\")\n",
    "\n",
    "# Confusion Matrix untuk model ensemble\n",
    "cm = confusion_matrix(y_test, y_pred_ensemble)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Non-Bot', 'Bot'], yticklabels=['Non-Bot', 'Bot'])\n",
    "plt.xlabel('Prediksi')\n",
    "plt.ylabel('Aktual')\n",
    "plt.title('Confusion Matrix - Model Ensemble')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../notebook/confusion_matrix.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"\\nConfusion Matrix telah disimpan sebagai 'confusion_matrix.png'\")\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report Model Ensemble:\")\n",
    "print(classification_report(y_test, y_pred_ensemble))\n",
    "\n",
    "# Cross Validation untuk model ensemble\n",
    "print(\"\\nCross Validation (5-Fold) untuk Model Ensemble:\")\n",
    "cv_scores = cross_val_score(ensemble_clf, X, y, cv=5, scoring='f1')\n",
    "print(f\"F1 Scores: {cv_scores}\")\n",
    "print(f\"Rata-rata F1 Score: {cv_scores.mean():.4f}\")\n",
    "print(f\"Standar Deviasi F1 Score: {cv_scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a7a3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. SIMPAN MODEL\n",
    "print(\"\\nLANGKAH 9: SIMPAN MODEL\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Simpan model ensemble\n",
    "model_path = \"model/kaggle_bot_detection_model.pkl\"\n",
    "with open(model_path, 'wb') as f:\n",
    "    pickle.dump(ensemble_clf, f)\n",
    "\n",
    "print(f\"Model telah disimpan ke: {model_path}\")\n",
    "\n",
    "# Simpan preprocessor secara terpisah (untuk digunakan di aplikasi)\n",
    "preprocessor_path = \"../model/preprocessor.pkl\"\n",
    "with open(preprocessor_path, 'wb') as f:\n",
    "    pickle.dump(preprocessor, f)\n",
    "\n",
    "print(f\"Preprocessor telah disimpan ke: {preprocessor_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d1ad5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. FEATURE IMPORTANCE ANALYSIS\n",
    "print(\"\\nLANGKAH 10: ANALISIS FEATURE IMPORTANCE\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Mendapatkan feature importance dari Random Forest (salah satu model dalam ensemble)\n",
    "rf_model = best_rf.named_steps['classifier']\n",
    "feature_names = []\n",
    "\n",
    "# Dapatkan nama fitur setelah preprocessing\n",
    "# Untuk fitur numerik\n",
    "feature_names.extend(numerical_cols)\n",
    "\n",
    "# Untuk fitur kategorikal yang di-one-hot-encode\n",
    "ohe = best_rf.named_steps['preprocessor'].transformers_[1][1].named_steps['onehot']\n",
    "categorical_features = [col for col in categorical_cols if col not in binary_cols]\n",
    "cat_feature_names = ohe.get_feature_names_out(categorical_features)\n",
    "feature_names.extend(cat_feature_names)\n",
    "\n",
    "# Potong ke jumlah fitur sebenarnya jika ada perbedaan\n",
    "n_features = len(rf_model.feature_importances_)\n",
    "feature_names = feature_names[:n_features]\n",
    "\n",
    "# Plot feature importance\n",
    "importance = rf_model.feature_importances_\n",
    "indices = np.argsort(importance)[::-1]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title('Feature Importance dari Random Forest')\n",
    "plt.bar(range(len(indices[:15])), importance[indices[:15]], align='center')\n",
    "plt.xticks(range(len(indices[:15])), [feature_names[i] for i in indices[:15]], rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../notebook/feature_importance.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"Feature importance telah disimpan sebagai 'feature_importance.png'\")\n",
    "\n",
    "print(\"\\nPROSES PELATIHAN MODEL SELESAI!\")\n",
    "print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virEnvironment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
